---
title: "Machine Learning Group Project 1"
author: "Jesse DeBolt and Isaac Johnson"
date: "2023-01-25"
output: html_document
---

## Setup

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(formatR)
library(moderndive)
library(caret)
library(class)
library(fastDummies)

wine <- read_rds("../pinot.rds")

```


## Feature Engineering from 1/24 class:
```{r}

# bin or exclude continuous (price, points)

wino <- wine %>% 
  rename_all(funs(tolower(.))) %>% 
  rename_all(funs(str_replace_all(., "-", "_"))) %>% 
  rename_all(funs(str_replace_all(., " ", "_"))) %>% 
  mutate(old = str_detect(description, " old")) %>% 
  mutate(village = str_detect(description, "[Vv]illage")) %>% 
  mutate(northern = str_detect(description, "[Nn]orthern")) %>%
  mutate(acidity = str_detect(description, "[Aa]cidity")) %>%
  mutate(aromas = str_detect(description, "[Aa]romas")) %>%
  mutate(black = str_detect(description, "[Bb]lack")) %>%
  mutate(notes = str_detect(description, "[Nn]otes")) %>%
  mutate(plum = str_detect(description, "[Pp]lum")) %>%
  mutate(plum = str_detect(description, "[Rr]ed")) %>% 
  select(-description) %>% 
  drop_na(.)

head(wino) %>% 
  select(1:8)
```

## Setting train, fitting model
```{r}
set.seed(504)
wine_index <- createDataPartition(wino$province, p = 0.8, list = FALSE)
train <- wino[ wine_index, ]
test <- wino[-wine_index, ]

fit <- knn(
  train = select(train,-province), 
  test = select(test,-province), 
  k=5, 
  cl = train$province, 
  prob = T)

```


## Confusion matrix

```{r tidy=T, strip.white=T, comment=""}
confusionMatrix(fit,factor(test$province))
```

## Basic model with parameter tuning

```{r}
control <- trainControl(method = "boot", number = 1)
fit <- train(province ~ .,
             data = train, 
             method = "knn",
             tuneLength = 15,
             trControl = control)
fit
```


## Confusion Matrix
```{r}
confusionMatrix(predict(fit, test),factor(test$province))
```


## With parameter tuning and subsampling

```{r}
fit <- train(province ~ .,
             data = train, 
             method = "knn",
             tuneLength = 15,
             metric = "Kappa",
             trControl = control)

fit
```

## Confusion Matrix
```{r}
confusionMatrix(predict(fit, test),factor(test$province))
```

## Tuning plot

```{r}
ggplot(fit, metric="Kappa")

```

## A new model
### Naive Bayes
```{r}
set.seed(504)
wine_index <- createDataPartition(wino$province, p = 0.80, list = FALSE)
train <- wino[ wine_index, ]
test <- wino[-wine_index, ]

fit <- train(province ~ .,
             data = train, 
             method = "naive_bayes",
             tuneGrid = expand.grid(usekernel = c(T,F), laplace = T, adjust = T),
                #can specify additional parameter/details for the algorithum to use
             metric = "Kappa",
             trControl = trainControl(method = "cv"))
fit
```

...now things are getting better.

## Confusion Matrix
```{r}
confusionMatrix(predict(fit, test),factor(test$province))

```
